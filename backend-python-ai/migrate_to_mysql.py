"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šä»å†…å­˜å­˜å‚¨è¿ç§»åˆ°MySQL

ä½¿ç”¨æ–¹æ³•:
1. ç¡®ä¿MySQLå·²å¯åŠ¨å¹¶åˆ›å»ºäº†æ•°æ®åº“
2. è¿è¡Œ: python migrate_to_mysql.py

æ³¨æ„: æ­¤è„šæœ¬åº”åœ¨åº”ç”¨å¯åŠ¨å‰è¿è¡Œä¸€æ¬¡
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from datetime import datetime
from sqlalchemy.orm import Session

from app.db import SessionLocal, init_db
from app.db.repositories import (
    employee_repository,
    knowledge_repository,
    conversation_repository
)
from app.db.models import (
    User, Organization, Employee,
    KnowledgeBase, KnowledgeItem,
    Conversation, Message,
    HireRecord, TrialRecord
)
from app.utils.logger import get_logger

logger = get_logger(__name__)


class DataMigrator:
    """æ•°æ®è¿ç§»å™¨"""
    
    def __init__(self):
        self.db: Session = SessionLocal()
        self.stats = {
            "organizations": 0,
            "users": 0,
            "employees": 0,
            "knowledge_bases": 0,
            "knowledge_items": 0,
            "conversations": 0,
            "messages": 0,
            "hire_records": 0,
            "trial_records": 0,
        }
    
    def migrate_all(self):
        """æ‰§è¡Œæ‰€æœ‰è¿ç§»"""
        logger.info("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»...")
        
        try:
            # åˆå§‹åŒ–æ•°æ®åº“è¡¨
            logger.info("ğŸ“¦ åˆå§‹åŒ–æ•°æ®åº“è¡¨...")
            init_db()
            
            # è¿ç§»ç»„ç»‡
            self.migrate_organizations()
            
            # è¿ç§»ç”¨æˆ·
            self.migrate_users()
            
            # è¿ç§»å‘˜å·¥
            self.migrate_employees()
            
            # è¿ç§»çŸ¥è¯†åº“
            self.migrate_knowledge_bases()
            
            # è¿ç§»å¯¹è¯
            self.migrate_conversations()
            
            # æäº¤æ‰€æœ‰æ›´æ”¹
            self.db.commit()
            
            # è¾“å‡ºç»Ÿè®¡
            self.print_stats()
            
            logger.info("âœ… æ•°æ®è¿ç§»å®Œæˆï¼")
            
        except Exception as e:
            self.db.rollback()
            logger.error(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {str(e)}", exc_info=True)
            raise
        finally:
            self.db.close()
    
    def migrate_organizations(self):
        """è¿ç§»ç»„ç»‡æ•°æ®"""
        logger.info("ğŸ¢ è¿ç§»ç»„ç»‡æ•°æ®...")
        
        # åˆ›å»ºé»˜è®¤ç»„ç»‡
        default_org = Organization(
            id="org_default",
            name="é»˜è®¤ç»„ç»‡",
            description="ç³»ç»Ÿé»˜è®¤ç»„ç»‡",
            status="active"
        )
        self.db.add(default_org)
        self.stats["organizations"] = 1
        
        logger.info("âœ… ç»„ç»‡æ•°æ®è¿ç§»å®Œæˆ")
    
    def migrate_users(self):
        """è¿ç§»ç”¨æˆ·æ•°æ®"""
        logger.info("ğŸ‘¤ è¿ç§»ç”¨æˆ·æ•°æ®...")
        
        # åˆ›å»ºç³»ç»Ÿç”¨æˆ·
        system_user = User(
            id="system",
            username="system",
            email="system@mekai.ai",
            organization_id="org_default",
            role="admin",
            status="active"
        )
        self.db.add(system_user)
        
        # åˆ›å»ºåŒ¿åç”¨æˆ·
        anonymous_user = User(
            id="anonymous",
            username="anonymous",
            organization_id="org_default",
            role="guest",
            status="active"
        )
        self.db.add(anonymous_user)
        
        self.stats["users"] = 2
        logger.info("âœ… ç”¨æˆ·æ•°æ®è¿ç§»å®Œæˆ")
    
    def migrate_employees(self):
        """è¿ç§»å‘˜å·¥æ•°æ®"""
        logger.info("ğŸ¤– è¿ç§»å‘˜å·¥æ•°æ®...")
        
        # ä»æ—§æœåŠ¡å¯¼å…¥æ•°æ®
        try:
            from app.services.employee_service import employee_service
            
            # è·å–å†…å­˜ä¸­çš„å‘˜å·¥æ•°æ®
            old_employees = getattr(employee_service, '_employees', {})
            
            for emp_id, emp_data in old_employees.items():
                employee_record = {
                    "id": emp_data.get("id", emp_id),
                    "name": emp_data.get("name", "æœªå‘½åå‘˜å·¥"),
                    "description": emp_data.get("description", ""),
                    "avatar": emp_data.get("avatar"),
                    "category": emp_data.get("category", []),
                    "tags": emp_data.get("tags", []),
                    "price": str(emp_data.get("price", "0")),
                    "original_price": emp_data.get("original_price"),
                    "trial_count": emp_data.get("trial_count", 0),
                    "hire_count": emp_data.get("hire_count", 0),
                    "is_hired": emp_data.get("is_hired", False),
                    "is_recruited": emp_data.get("is_recruited", False),
                    "status": emp_data.get("status", "draft"),
                    "skills": emp_data.get("skills", []),
                    "knowledge_base_ids": emp_data.get("knowledge_base_ids", []),
                    "industry": emp_data.get("industry"),
                    "role": emp_data.get("role"),
                    "prompt": emp_data.get("prompt"),
                    "model": emp_data.get("model", "deepseek-chat"),
                    "is_hot": emp_data.get("is_hot", False),
                    "personality": emp_data.get("personality"),
                    "welcome_message": emp_data.get("welcome_message"),
                    "created_by": emp_data.get("created_by", "system"),
                    "organization_id": emp_data.get("organization_id", "org_default"),
                    "created_at": emp_data.get("created_at", datetime.utcnow()),
                    "updated_at": emp_data.get("updated_at", datetime.utcnow()),
                }
                
                employee_repository.create(self.db, obj_in=employee_record)
                self.stats["employees"] += 1
            
            logger.info(f"âœ… å‘˜å·¥æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {self.stats['employees']} æ¡")
            
        except Exception as e:
            logger.warning(f"âš ï¸ å‘˜å·¥æ•°æ®è¿ç§»è·³è¿‡: {str(e)}")
    
    def migrate_knowledge_bases(self):
        """è¿ç§»çŸ¥è¯†åº“æ•°æ®"""
        logger.info("ğŸ“š è¿ç§»çŸ¥è¯†åº“æ•°æ®...")
        
        try:
            from app.services.knowledge.knowledge_service import knowledge_service
            
            # è¿ç§»çŸ¥è¯†åº“
            old_kbs = getattr(knowledge_service, '_knowledge_bases', {})
            
            for kb_id, kb_data in old_kbs.items():
                kb_record = {
                    "id": kb_data.get("id", kb_id),
                    "name": kb_data.get("name", "æœªå‘½åçŸ¥è¯†åº“"),
                    "description": kb_data.get("description", ""),
                    "category": kb_data.get("category"),
                    "doc_count": kb_data.get("doc_count", 0),
                    "created_by": kb_data.get("created_by", "system"),
                    "organization_id": kb_data.get("organization_id", "org_default"),
                    "status": kb_data.get("status", "active"),
                    "tags": kb_data.get("tags", []),
                    "is_public": kb_data.get("is_public", True),
                    "vectorized": kb_data.get("vectorized", False),
                    "embedding_model": kb_data.get("embedding_model", "text-embedding-3-small"),
                    "vector_store_path": kb_data.get("vector_store_path"),
                    "settings": kb_data.get("settings", {}),
                    "created_at": kb_data.get("created_at", datetime.utcnow()),
                    "updated_at": kb_data.get("updated_at", datetime.utcnow()),
                }
                
                knowledge_repository.create_kb(self.db, obj_in=kb_record)
                self.stats["knowledge_bases"] += 1
                
                # è¿ç§»çŸ¥è¯†ç‚¹
                old_items = getattr(knowledge_service, '_knowledge_items', {}).get(kb_id, [])
                for i, item_data in enumerate(old_items, start=1):
                    item_record = {
                        "id": item_data.get("id", f"{kb_id}_item_{i}"),
                        "knowledge_base_id": kb_id,
                        "serial_no": item_data.get("serial_no", i),
                        "content": item_data.get("content", ""),
                        "word_count": item_data.get("word_count", 0),
                        "source_file": item_data.get("source_file"),
                        "metadata": item_data.get("metadata", {}),
                    }
                    
                    self.db.add(KnowledgeItem(**item_record))
                    self.stats["knowledge_items"] += 1
            
            logger.info(f"âœ… çŸ¥è¯†åº“æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {self.stats['knowledge_bases']} ä¸ªçŸ¥è¯†åº“ï¼Œ{self.stats['knowledge_items']} ä¸ªçŸ¥è¯†ç‚¹")
            
        except Exception as e:
            logger.warning(f"âš ï¸ çŸ¥è¯†åº“æ•°æ®è¿ç§»è·³è¿‡: {str(e)}")
    
    def migrate_conversations(self):
        """è¿ç§»å¯¹è¯æ•°æ®"""
        logger.info("ğŸ’¬ è¿ç§»å¯¹è¯æ•°æ®...")
        
        try:
            from app.services.memory.conversation_memory import conversation_memory_manager
            
            # è¿ç§»å¯¹è¯
            old_convs = getattr(conversation_memory_manager, '_conversations', {})
            
            for conv_id, conv_data in old_convs.items():
                conv_record = {
                    "id": conv_data.get("id", conv_id),
                    "employee_id": conv_data.get("employee_id", "unknown"),
                    "user_id": conv_data.get("user_id"),
                    "organization_id": conv_data.get("organization_id", "org_default"),
                    "title": conv_data.get("title", "æœªå‘½åå¯¹è¯"),
                    "message_count": conv_data.get("message_count", 0),
                    "status": conv_data.get("status", "active"),
                    "metadata": conv_data.get("metadata", {}),
                    "created_at": conv_data.get("created_at", datetime.utcnow()),
                    "updated_at": conv_data.get("updated_at", datetime.utcnow()),
                }
                
                conversation_repository.create_conversation(self.db, obj_in=conv_record)
                self.stats["conversations"] += 1
                
                # è¿ç§»æ¶ˆæ¯
                messages = conv_data.get("messages", [])
                for msg_data in messages:
                    msg_record = {
                        "id": msg_data.get("id", f"{conv_id}_msg_{len(messages)}"),
                        "conversation_id": conv_id,
                        "role": msg_data.get("role", "user"),
                        "content": msg_data.get("content", ""),
                        "token_count": msg_data.get("token_count"),
                        "model": msg_data.get("model"),
                        "metadata": msg_data.get("metadata", {}),
                        "created_at": msg_data.get("created_at", datetime.utcnow()),
                    }
                    
                    self.db.add(Message(**msg_record))
                    self.stats["messages"] += 1
            
            logger.info(f"âœ… å¯¹è¯æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {self.stats['conversations']} ä¸ªå¯¹è¯ï¼Œ{self.stats['messages']} æ¡æ¶ˆæ¯")
            
        except Exception as e:
            logger.warning(f"âš ï¸ å¯¹è¯æ•°æ®è¿ç§»è·³è¿‡: {str(e)}")
    
    def print_stats(self):
        """æ‰“å°è¿ç§»ç»Ÿè®¡"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š æ•°æ®è¿ç§»ç»Ÿè®¡")
        logger.info("="*60)
        for key, value in self.stats.items():
            logger.info(f"  {key}: {value}")
        logger.info("="*60 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸš€ MEK-AI æ•°æ®è¿ç§»å·¥å…·")
    print("="*60 + "\n")
    
    # ç¡®è®¤
    confirm = input("ç¡®è®¤è¦å°†æ•°æ®è¿ç§»åˆ°MySQLå—ï¼Ÿè¿™å°†æ¸…ç©ºç°æœ‰æ•°æ® [y/N]: ")
    if confirm.lower() != 'y':
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return
    
    # æ‰§è¡Œè¿ç§»
    migrator = DataMigrator()
    migrator.migrate_all()
    
    print("\nâœ… è¿ç§»å®Œæˆï¼")


if __name__ == "__main__":
    main()
